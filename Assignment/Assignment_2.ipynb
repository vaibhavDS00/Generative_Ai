{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "768f4834",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Create a Doc object fCreate a Doc object from the file owlcreek.txtrom the file owlcreek.txtCreate a Doc object from the file owlcreek.txt\n",
    "import spacy\n",
    "nlp=spacy.load(\"en_core_web_sm\")\n",
    "with open(\"owlcreek.txt\", \"r\") as file:\n",
    "    text = file.read()\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "45747dde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens: 4835\n"
     ]
    }
   ],
   "source": [
    "# 2. How many tokens are contained in the file?\n",
    "num_tokens = len(doc)\n",
    "print(f\"Number of tokens: {num_tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a871d5c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences: 204\n"
     ]
    }
   ],
   "source": [
    "# 3. How many sentences are contained in the file?\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "nlp.add_pipe('sentencizer')\n",
    "doc = nlp(text)\n",
    "num_sentences = len(list(doc.sents))\n",
    "print(f\"Number of sentences: {num_sentences}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "87365cc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The man's hands were behind\n",
      "his back, the wrists bound with a cord.  \n"
     ]
    }
   ],
   "source": [
    "# 4. Print the second sentence in the document\n",
    "second_sentence = list(doc.sents)[1]\n",
    "print(second_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1e6dd1cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Token  POS  DEP  LEMMA\n",
      "The DET det the\n",
      "man NOUN poss man\n",
      "'s PART case 's\n",
      "hands NOUN nsubj hand\n",
      "were AUX ROOT be\n",
      "behind ADP prep behind\n",
      "\n",
      " SPACE dep \n",
      "\n",
      "his PRON poss his\n",
      "back NOUN pobj back\n",
      ", PUNCT punct ,\n",
      "the DET det the\n",
      "wrists NOUN appos wrist\n",
      "bound VERB acl bind\n",
      "with ADP prep with\n",
      "a DET det a\n",
      "cord NOUN pobj cord\n",
      ". PUNCT punct .\n",
      "  SPACE dep  \n"
     ]
    }
   ],
   "source": [
    "# 5. Token details from second sentence\n",
    "print(\"\\nToken  POS  DEP  LEMMA\")\n",
    "for token in second_sentence:\n",
    "    print(token.text, token.pos_, token.dep_, token.lemma_)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "62aac463",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Write a matcher called 'Swimming' that finds both occurrences of the phrase \"swimming vigorously\" in the text.\n",
    "matcher = Matcher(nlp.vocab)\n",
    "pattern = [\n",
    "    {\"LOWER\": \"swimming\"},\n",
    "    {\"LOWER\": \"vigorously\"}\n",
    "]\n",
    "matcher.add(\"Swimming\", [pattern])\n",
    "\n",
    "matches = matcher(doc)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2538297e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MATCHES FOUND:\n"
     ]
    }
   ],
   "source": [
    "# 7. Print the text surrounding each found match.\n",
    "print(\"\\nMATCHES FOUND:\")\n",
    "for match_id, start, end in matches:\n",
    "    span = doc[start-3 : end+3]   # 3 tokens before & after\n",
    "    print(span.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
